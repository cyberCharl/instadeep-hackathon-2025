{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPVUemGzkZXt"
      },
      "source": [
        "# MLIP hackathon starter notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZbvC8Gq3qPz"
      },
      "source": [
        "In this challenge, we train a Machine Learning Interatomic Potential (MLIP) model using the [`mlip`](https://github.com/instadeepai/mlip) library.\n",
        "\n",
        "If you run this on Google Colab, make sure to select a GPU runtime (Runtime > Change runtime type > Hardware accelerator > GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLsahv2MlU12"
      },
      "outputs": [],
      "source": [
        "!pip install mlip \"jax[cuda12]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nvEJG82QTrnx",
        "outputId": "82d80de3-6ebf-42b9-837d-5dafcf2b43f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (24.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bd0DkOGeScx"
      },
      "source": [
        "**Install, required imports, and logging setup**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "!wandb login"
      ],
      "metadata": {
        "id": "g6CVS1Z3T_xP",
        "outputId": "cc3bb185-c22d-4527-fe94-5926d1d25104",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcybercharl\u001b[0m (\u001b[33mcybercharl-ai-safety-south-africa\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7j0nxIefksNG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For dataset loading\n",
        "from mlip.data import GraphDatasetBuilder, ExtxyzReader\n",
        "\n",
        "# For model\n",
        "from mlip.models import Mace, Nequip, Visnet, ForceField\n",
        "\n",
        "# For optimizer\n",
        "import optax\n",
        "\n",
        "# For loss function\n",
        "from mlip.models.loss import MSELoss\n",
        "\n",
        "# For training\n",
        "from mlip.training import TrainingLoop\n",
        "from mlip.models.model_io import save_model_to_zip, load_model_from_zip\n",
        "from mlip.models.params_loading import load_parameters_from_checkpoint\n",
        "\n",
        "# For checkpointing\n",
        "from mlip.training import TrainingIOHandler, log_metrics_to_line\n",
        "from mlip.training.training_io_handler import LogCategory\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, force=True, format='%(levelname)s - %(message)s')\n",
        "\n",
        "# Set dedicated logging for mlip. Set this to logging.DEBUG to see more detailed logs.\n",
        "logging.getLogger(\"mlip\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru3fIT7Tq24A"
      },
      "source": [
        "Let's also check what device we are using:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7bAOYOrqxN8"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "\n",
        "print(jax.devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cksPWIwMkt-G"
      },
      "source": [
        "## 1. Preparing a dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkHNCGbVwyCK"
      },
      "source": [
        "For this example, we train on configurations of a molecule called [3-(benzyloxy)pyridin-2-amine](https://pubchem.ncbi.nlm.nih.gov/substance/854545) (molecular formula `C12H12N2O`, abbreviated as `3BPA`) sampled with Molecular Dynamics at a temperature of 300 Kelvin.\n",
        "\n",
        "It's molecular structure consists of a **pyridin-2-amine core**:\n",
        "\n",
        " * A **pyridine ring** (six-membered aromatic ring with one nitrogen atom).\n",
        "\n",
        " * An **amino group (-NH₂)** at the 2-position of the pyridine ring (adjacent to the nitrogen).\n",
        "\n",
        "Benzyloxy substituent at position 3:\n",
        "\n",
        " * A **benzyloxy group (-OCH₂C₆H₅)** is attached to the 3-position of the pyridine ring.\n",
        "\n",
        " * This consists of a **methylene bridge (–CH₂–)** bonded to a **phenyl ring (C₆H₅)**, connected via an **ether linkage (–O–)**.\n",
        "\n",
        "![3BPA](https://go.drugbank.com/structures/DB02352/thumb.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsWBkN4xlU14"
      },
      "source": [
        "The data processing **is a two step process**:\n",
        "\n",
        "1. **We read the data from disk into [`ChemicalSystem`](https://instadeepai.github.io/mlip/api_reference/data/chemical_system.html) objects**. This is done by a \"reader\", and since the dataset is stored in extended xyz format, it can be read with the [`ExtxyzReader`](https://instadeepai.github.io/mlip/api_reference/data/chemical_systems_readers/extxyz_reader.html). The *mlip* library also includes a HDF5 format reader: [`Hdf5Reader`](https://instadeepai.github.io/mlip/api_reference/data/chemical_systems_readers/hdf5_reader.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAV2wyZGlU15"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mkdir -p data\n",
        "\n",
        "[ -f data/test_public.xyz ] || wget -P data https://raw.githubusercontent.com/BioGeek/hackathon_IndabaX_2025_mlip/refs/heads/main/data/test_public.xyz\n",
        "[ -f data/train.xyz ] || wget -P data https://raw.githubusercontent.com/BioGeek/hackathon_IndabaX_2025_mlip/refs/heads/main/data/train.xyz\n",
        "[ -f data/validation.xyz ] || wget -P data https://raw.githubusercontent.com/BioGeek/hackathon_IndabaX_2025_mlip/refs/heads/main/data/validation.xyz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxbTwW74kwrN"
      },
      "outputs": [],
      "source": [
        "reader = ExtxyzReader(\n",
        "    ExtxyzReader.Config(\n",
        "        train_dataset_paths=\"data/train.xyz\",\n",
        "        valid_dataset_paths=\"data/validation.xyz\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkLW_jW2xS1t"
      },
      "source": [
        "2. **We process these [`ChemicalSystem`](https://instadeepai.github.io/mlip/api_reference/data/chemical_system.html) objects into graphs.** This process uses the class [`GraphDatasetBuilder`](https://instadeepai.github.io/mlip/api_reference/data/graph_dataset_builder.html) which offers some degree of customisation through its [config class](https://instadeepai.github.io/mlip/api_reference/data/dataset_configs.html#mlip.data.configs.GraphDatasetBuilderConfig).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXjGxXwul4kT"
      },
      "outputs": [],
      "source": [
        "builder_config = GraphDatasetBuilder.Config(\n",
        "    graph_cutoff_angstrom=5.0,\n",
        "    batch_size=16,\n",
        ")\n",
        "\n",
        "builder = GraphDatasetBuilder(reader, builder_config)\n",
        "builder.prepare_datasets() # This step is required to compute all dataset information (used later on by most MLIP model)\n",
        "\n",
        "train_set, validation_set, _ = builder.get_splits()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHq_F75zxb-D"
      },
      "source": [
        "More information can be found in the [deep-dive on data processing](https://instadeepai.github.io/mlip/user_guide/data_processing.html)  in our documentation for more details.\n",
        "\n",
        "We can now **print some statistics about our dataset** along with the [`DatasetInfo`](https://instadeepai.github.io/mlip/api_reference/data/dataset_info.html) object that will be required for downstream tasks. The **dataset info** holds all the hyperparameters of the models that are directly derived from the dataset or its processing, e.g., the cutoff distance to determine the graph edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6cER4-oroyQ"
      },
      "outputs": [],
      "source": [
        "print(\"Dataset info:\", builder.dataset_info)\n",
        "print(\"Number of batches in train set:\", len(train_set))\n",
        "print(\"Number of batches in validation set:\", len(validation_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGTiyZ1IlU15"
      },
      "source": [
        "The atomic energies and forces are stored in the `energy` and `forces` attributes of the [`ChemicalSystem`](https://instadeepai.github.io/mlip/api_reference/data/chemical_system.html) objects, respectively. The energies are in [eV](https://en.wikipedia.org/wiki/Electronvolt), and the forces are in eV/[Å](https://en.wikipedia.org/wiki/Angstrom)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts8Pv7Aqo0wp"
      },
      "source": [
        "## 2. Preparing a training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5_9_VPfxmIr"
      },
      "source": [
        "To start training, we first need to prepare some prerequisites. These are, as for all ML models:\n",
        "- A **model architecture**,\n",
        "- An **optimizer**, and\n",
        "- A **loss function**\n",
        "\n",
        "We start with the **model architecture**:\n",
        "\n",
        "We can use one of the pre-defined models in the *mlip* library, such as MACE, NequIP, or ViSNet. These models are designed to handle molecular graphs and can be configured with various hyperparameters.\n",
        "\n",
        "For this tutorial, we provide the initialization code for MACE, NequIP and ViSnet, but commented out two of them. For all the hyperparameters available, see the documentations of the [MACE config](https://instadeepai.github.io/mlip/api_reference/models/mace.html#mlip.models.mace.config.MaceConfig), the [NequIP config](https://instadeepai.github.io/mlip/api_reference/models/nequip.html#mlip.models.nequip.config.NequipConfig), and the [ViSNet config](https://instadeepai.github.io/mlip/api_reference/models/visnet.html#mlip.models.visnet.config.VisnetConfig).\n",
        "\n",
        "The model creation process includes two steps:\n",
        "* 1: the creation of the MLIP network and\n",
        "* 2:the creation  of the force field.\n",
        "\n",
        "See our [deep-dive on models](https://instadeepai.github.io/mlip/user_guide/models.html) for a detailed explanation of this pattern.\n",
        "\n",
        "**Hint**: try some of the other pre-defined models by uncommenting the lines below and running the cell again. You can also try to change some of the hyperparameters in the config classes, e.g., the number of layers or channels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    # Set the wandb entity where your project will be logged (generally your team name).\n",
        "    entity=\"cyberCharl\",\n",
        "    # Set the wandb project where this run will be logged.\n",
        "    project=\"Instadeep Hackathon\",\n",
        "    # Track hyperparameters and run metadata.\n",
        "    config={\n",
        "        \"epochs\": 100,\n",
        "        \"node_irreps\": \"4x0e + 4x0o + 4x1o + 4x1e + 4x2e + 4x2o\",\n",
        "        \"num_layers\": 4,\n",
        "        \"weight_decay\": 1e-5,\n",
        "        \"grad_norm\": 50,\n",
        "        \"num_gradient_accumulation_steps\": 1,\n",
        "        \"init_learning_rate\": 5e-4,  # Start a bit higher\n",
        "        \"peak_learning_rate\": 2e-3,  # Target higher peak\n",
        "        \"final_learning_rate\": 1e-4,  # Decay to a lower final LR\n",
        "        \"warmup_steps\": 10000,  # Adjusted for your dataset size and epoch count (approx 5 epochs)\n",
        "        \"transition_steps\": 1840000,\n",
        "        \"energy_weight\": 500.0\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "Y54QCG8GVOou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4VU3zb6o1_9"
      },
      "outputs": [],
      "source": [
        "# We override some of the default hyperparameters\n",
        "# of the model to make it smaller such that this training example becomes more minimal\n",
        "# mlip_network = Mace(\n",
        "#     Mace.Config(num_channels=16, correlation=2),\n",
        "#     builder.dataset_info,\n",
        "# )\n",
        "\n",
        "# New, potentially larger MACE setup:\n",
        "# Consider if statement based on architecture\n",
        "mlip_network = Nequip(\n",
        "    Nequip.Config(\n",
        "        node_irreps=run.config[\"node_irreps\"],\n",
        "        num_layers=run.config[\"num_layers\"],\n",
        "    ),\n",
        "    builder.dataset_info,\n",
        ")\n",
        "\n",
        "# mlip_network = Visnet(\n",
        "#     Visnet.Config(num_channels=16, num_layers=2),\n",
        "#     builder.dataset_info,\n",
        "# )\n",
        "\n",
        "mlip_network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZPgyPdplU16"
      },
      "source": [
        "The force field will be the essential object required for the training below, as well as for running MD simulations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJmZ6EmzlU16"
      },
      "outputs": [],
      "source": [
        "force_field = ForceField.from_mlip_network(mlip_network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj6OHwN3x3uu"
      },
      "source": [
        "Next, we **create an optimizer**:\n",
        "\n",
        "The *mlip* library is set up so that you can use any [`optax`](https://github.com/google-deepmind/optax) optimizer you like, here we've chosen for [`optax.adam`](https://optax.readthedocs.io/en/latest/api/optimizers.html#optax.adam).\n",
        "\n",
        "**Hint:** Also try an optimizer specialized for MLIP models (see [this](https://instadeepai.github.io/mlip/api_reference/training/optimizer.html#mlip.training.optimizer.get_default_mlip_optimizer) part of the documentation for more details)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PRdkIPopJc4",
        "outputId": "0aeee4ab-a07c-49e7-8b3a-5fe08c0b7e14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x7a5ff1262d40>, update=<function chain.<locals>.update_fn at 0x7a5ff17477e0>)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "from mlip.training.optimizer import get_default_mlip_optimizer\n",
        "from mlip.training.optimizer_config import OptimizerConfig\n",
        "\n",
        "# Configure the specialized MLIP optimizer\n",
        "optimizer_config = OptimizerConfig(\n",
        "    apply_weight_decay_mask=True,\n",
        "    weight_decay= run.config[\"weight_decay\"],\n",
        "    grad_norm=run.config[\"grad_norm\"],\n",
        "    num_gradient_accumulation_steps=run.config[\"num_gradient_accumulation_steps\"],\n",
        "    init_learning_rate=run.config[\"init_learning_rate\"],\n",
        "    peak_learning_rate=run.config[\"peak_learning_rate\"],\n",
        "    final_learning_rate=run.config[\"final_learning_rate\"]\n",
        "    warmup_steps=run.config[\"warmup_steps\"],\n",
        "    transition_steps=run.config[\"transition_steps\"]\n",
        ")\n",
        "\n",
        "optimizer = get_default_mlip_optimizer(optimizer_config)\n",
        "\n",
        "print(\"Loss function:\", loss)\n",
        "print(\"Optimizer configuration:\", optimizer_config)\n",
        "print(\"Optimizer:\", optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47NWAw7uyL3D"
      },
      "source": [
        "For the **loss**:\n",
        "\n",
        "We use a Mean-Squared-Error (MSE) loss, that by default uses a weighting factor of 25.0 for MSE of forces, 1.0 for MSE of energies, and zero for MSE of stress (which is not available in this dataset). See [this](https://instadeepai.github.io/mlip/user_guide/training.html#loss) part of the documentation for more information on further options such as alternative loss functions and how to create a weight flip schedule between energy and forces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj4d_ZoopJa6"
      },
      "outputs": [],
      "source": [
        "loss = MSELoss()\n",
        "\n",
        "energy_weight_schedule = optax.piecewise_constant_schedule(500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7qOM_vSlU16"
      },
      "source": [
        "We can now set up a **custom I/O handler** with checkpointing for training:\n",
        "\n",
        "The I/O handler class is documented [here](https://instadeepai.github.io/mlip/api_reference/training/training_io_handling.html). Also check out [this](https://instadeepai.github.io/mlip/user_guide/training.html#io-handling-and-logging) part in our deep-dive on logging for more information. The code below adds a local directory for checkpointing to the I/O handler, which activates checkpointing during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoaaXD7NlU16"
      },
      "outputs": [],
      "source": [
        "io_handler = TrainingIOHandler(\n",
        "    TrainingIOHandler.Config(\n",
        "        local_model_output_dir=\"training/model_training\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVptSCsulU16"
      },
      "source": [
        "Next, we can **attach logging functions to the I/O handler**:\n",
        "\n",
        "Users can attached as many logging functions as required to the I/O handler. In this example, we attach two.\n",
        "1. The [`log_metrics_to_line`](https://instadeepai.github.io/mlip/api_reference/training/training_io_handling.html#mlip.training.training_loggers.log_metrics_to_line) function that is also included in the default I/O handler that we used in the previous example.\n",
        "2. A custom function that just keeps track of the validation set losses, so we can later easily create a curve from it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvGu40RYlU16"
      },
      "outputs": [],
      "source": [
        "# The following logger is also attached in the default I/O handler\n",
        "# that was used in the training above\n",
        "io_handler.attach_logger(log_metrics_to_line)\n",
        "\n",
        "# Define a custom logging function that keeps track of validation loss\n",
        "validation_losses = []\n",
        "training_losses = []\n",
        "def _custom_logger(category, to_log, epoch_number):\n",
        "  if category == LogCategory.EVAL_METRICS:\n",
        "    validation_losses.append(to_log[\"loss\"])\n",
        "  elif category == LogCategory.TRAIN_METRICS:\n",
        "    training_losses.append(to_log[\"loss\"])\n",
        "\n",
        "# Attach our custom logging function to the I/O handler\n",
        "io_handler.attach_logger(_custom_logger)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zskGftVJlU16"
      },
      "source": [
        "The custom logging function is called several times during the training loop with the argument `category` (e.g. `TRAIN_METRICS`, `EVAL_METRICS`) telling the function what is currently being logged, for example, train or evaluation metrics. It is of enum type [`LogCategory`](https://instadeepai.github.io/mlip/api_reference/training/training_io_handling.html#mlip.training.training_io_handler.LogCategory). See the documentation of the built-in function [`log_metrics_to_line`](https://instadeepai.github.io/mlip/api_reference/training/training_io_handling.html#mlip.training.training_loggers.log_metrics_to_line) for what we expect the logging function's signature to be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zjiQX3d3EsK"
      },
      "source": [
        "Finally, we can **create our training loop**:\n",
        "\n",
        "At a minimum, it needs as input:\n",
        "- a training dataset\n",
        "- a validation dataset\n",
        "- a force field\n",
        "- a loss\n",
        "- an optimizer\n",
        "- a config (which specifies for instace the number of epochs)\n",
        "\n",
        "Note that the config is documented [here](https://instadeepai.github.io/mlip/api_reference/training/training_loop_config.html). Its only argument that lacks a default value is the number of epochs to train for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyNXJW6SurAD",
        "outputId": "4d52370c-a2f7-4d86-c09d-c7c95dca2ba3",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - Number of parameters: 59626\n",
            "INFO - Number of parameters in optimizer: 119253\n"
          ]
        }
      ],
      "source": [
        "training_config = TrainingLoop.Config(\n",
        "    num_epochs=run.config[\"epochs\"],\n",
        "    energy_weight=run.config[\"energy_weight\"],\n",
        "    force_weight=0, # Reduce this to make energy more important\n",
        ")\n",
        "\n",
        "training_loop = TrainingLoop(\n",
        "    train_dataset=train_set,\n",
        "    validation_dataset=validation_set,\n",
        "    force_field=force_field,\n",
        "    loss=loss,\n",
        "    optimizer=optimizer,\n",
        "    config=training_config,\n",
        "    io_handler=io_handler,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecbtfdFa8iJc"
      },
      "source": [
        "## 3. Running a training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTre9bQD3IbJ"
      },
      "source": [
        "**Running the loop**:\n",
        "\n",
        "The following box runs the prepared training loop. Note that training will be a **lot more efficient for GPU users** (depending on the GPU, one should expect ~1s to ~12s per epoch, once the code is compiled) - for CPU users our measures ranged from ~12s to ~100s per epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eef9QrDPvJs7"
      },
      "outputs": [],
      "source": [
        "training_loop.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ie0uQOvlU17"
      },
      "source": [
        "We can now **access the information stored** by the custom logger saved into our validation loss list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxi-fYGglU17"
      },
      "outputs": [],
      "source": [
        "print(validation_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmIME-wylU17"
      },
      "source": [
        "Let's create a training curve from these values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEOjLHKZlU1-"
      },
      "outputs": [],
      "source": [
        "epoch_nums = list(range(len(validation_losses)))\n",
        "epoch_nums = list(range(len(training_losses)))\n",
        "plt.plot(epoch_nums, training_losses, c=\"red\")\n",
        "plt.plot(epoch_nums, validation_losses, c=\"blue\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Validation loss (blue) & Training Loss (red)\")\n",
        "plt.xticks(epoch_nums)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRPpV0CBlU1-"
      },
      "source": [
        "**Recovering the best validation model**:\n",
        "\n",
        "After training has completed, the [`TrainingLoop`](https://instadeepai.github.io/mlip/api_reference/training/training_loop.html) holds all the relevant information about the run. We can obtain the force field with the best validation parameters as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSrWZFsZlU1_"
      },
      "outputs": [],
      "source": [
        "best_force_field = training_loop.best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWeaguhglU1_"
      },
      "source": [
        "This force field object can now be applied in, for example, MD simulations or energy minimizations.\n",
        "\n",
        "Furthermore, these checkpoints can of course also be **used to restart a training from a given checkpoint**. We refer to the [documentation of the I/O handler's config](https://instadeepai.github.io/mlip/api_reference/training/training_io_handling.html#mlip.training.training_io_handler.TrainingIOHandlerConfig) for more information on this.\n",
        "\n",
        "**Saving the model to a zip file**:\n",
        "\n",
        "We can also save the trained model in zip format. This is also the format that we provide our pre-trained models in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Euv-3G-mlU1_"
      },
      "outputs": [],
      "source": [
        "save_model_to_zip(\"training/my_final_model.zip\", best_force_field)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMlcfZUalU1_"
      },
      "source": [
        "**Loading a pre-trained model**\n",
        "\n",
        "We can also load a pre-trained model from a zip file. This is useful if you want to use a pre-trained model for inference or fine-tuning on a different dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lZ0VpBPlU1_"
      },
      "outputs": [],
      "source": [
        "best_force_field = load_model_from_zip(Mace, \"training/my_final_model.zip\")\n",
        "\n",
        "print(\"Dataset info:\", best_force_field.dataset_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZZeNap6lU1_"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U14qTi5slU1_"
      },
      "source": [
        "The model will be tested on its ability to predict the energies of new conformations\n",
        "of the same molecule. However, to test the generalization\n",
        "capabilities of the model, these conformations are sampled at higher temperature,\n",
        "i.e., 1200 Kelvin. The test conformations are located in the\n",
        "`test_public.xyz` file. You can predict energies for them with a model saved in the\n",
        "zip format with the mlip library's batched inference functionality, described\n",
        "[here](https://instadeepai.github.io/mlip/user_guide/simulations.html#batched-inference)\n",
        "in the mlip documentation or explained in section 2 of\n",
        "[mlip's simulation tutorial](https://github.com/instadeepai/mlip/blob/main/tutorials/simulation_tutorial.ipynb).\n",
        "The public leaderboard contains the target energies. The metric the predictions will be scored on is root-mean-square error (RMSE).\n",
        "\n",
        "\n",
        "**Hint**: to get the best energies, you want to put higher weights on energies during training which is not the case in the default settings, where forces are more highly weighted.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpslpHjC2r0Z"
      },
      "outputs": [],
      "source": [
        "from ase.io import read as ase_read\n",
        "\n",
        "test_data = \"data/test_public.xyz\"\n",
        "structures = ase_read(test_data, index=\":\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPbZlFAflU1_"
      },
      "source": [
        "We can now run inference with a single pre-built function, note Jax starts by compiling all the required functions. It may appear slow at the beginning but this provides significant acceleration at scales (compilation is saved in the notebook kernel, so if you want an illustration of the speed gains, you can run the cell twice):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2ZMvIJllU1_"
      },
      "outputs": [],
      "source": [
        "from mlip.inference import run_batched_inference\n",
        "\n",
        "predictions = run_batched_inference(structures, best_force_field, batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtxCDi26lU1_"
      },
      "source": [
        "# Get your output into submission format\n",
        "\n",
        "We need to get our outputs into their \"camera-ready\" form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGNFfcb5lU1_"
      },
      "outputs": [],
      "source": [
        "energies = np.array([prediction.energy for prediction in predictions])\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'ID': np.arange(len(energies)),\n",
        "    'energies': energies\n",
        "})\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WPAFZnalU1_"
      },
      "outputs": [],
      "source": [
        "your_name = \"YOUR_NAME_HERE\"\n",
        "filename = f\"{your_name}_submission.csv\"\n",
        "df.to_csv(filename, index=False)\n",
        "print(f\"Saved submission to {filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNi3n4JfSUS2"
      },
      "source": [
        "Submit your solution by uploading the CSV file to the [Zindi competition page](https://zindi.africa/competitions/indabax-south-africa-2025-hackathon-with-instadeep)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hackathon_IndabaX_2025_mlip",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}